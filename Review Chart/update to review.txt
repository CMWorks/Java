Update:
I have read and taken into consideration a lot of your guy's feedback and I have updated the data to more accurately filter out all of the spam.

Disclaimer: this new set of data was collected July 3 at noon CST. I had to re-scrape the data since I didn't save the actual review text the first time around
Also warning. I use more statistical terminology in this update compared to the original post, so don't complain if you have no idea what I am saying.
Data:
Instead of eliminating an entire score by the trend of the reviews/days, I decided to calculate a cutoff limit so that any review size less than x would be counted as spam. Also, since someone mentioned it, any review that contain profanity would also be counted as spam.
I decided to use Q1 as my cut off limit as that would mark 25% of the comments as spam and 75% of the comments as legitimate. The problem with calculating Q1 directly with the raw data is that since the data is skewed right, Q1 would be disproportionately low. I calculated it to be 189.
In order to fix this problem, I used the fact that if you take multiple different subset of main data set, then use the mean values of each subset as values of a new set, it would be normally distributed, no matter how skewed the original data was. So I wrote a new program that would create 100000 subsets, each with 50 random reviews. I calculated the mean review length for each one and used that data to form a new set of data. From that, I calculated a mean of 622, a standerd deviation of 110, and Q1=544.
Now, this is where I have to go against standard practeces and make my own. Normaly, you would calcualte the IQR and find a lower and upper bound, and any data that falls out of theat bounds is considered outliers. The problem with doing that in our case is that longer reviews are, for the most part, not spam. So instead, I just decied to use the first quartile instead of the lower and upper bounds and considered any reveiw below 544 to be spam. (just an fyi, the different from using Q1 insted of the lower bound is only 7484 reviews, so it realy does not make a difference).

Conclusion:
